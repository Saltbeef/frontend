name: Analyze House

on:
  workflow_dispatch:
    inputs:
      house_id:
        description: 'Unique ID of the house to analyze'
        required: true
        type: string
      rules_version:
        description: 'Version of analysis rules to use (e.g., v1.0.0 or latest)'
        required: false
        default: 'latest'
        type: string
      llm_provider:
        description: 'LLM provider to use (mock, claude, openai)'
        required: false
        default: 'claude'
        type: choice
        options:
          - mock
          - claude
          - openai

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: write  # Required to push to main branch

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main  # Always work on main branch
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # No external dependencies needed - using stdlib only

      - name: Fetch house data from compressed dataset
        id: fetch_data
        run: |
          HOUSE_ID="${{ inputs.house_id }}"

          echo "Extracting house ${HOUSE_ID} from compressed dataset..."

          # Decompress dataset
          gunzip -c data/apify_dataset.json.gz > dataset_temp.json

          # Extract specific house data using jq
          jq --arg house_id "${HOUSE_ID}" '.[] | select(.Identifiers.TinyId == $house_id)' dataset_temp.json > house_data.json

          # Check if house was found
          if [ ! -s house_data.json ] || [ "$(cat house_data.json)" = "null" ]; then
            echo "ERROR: House ${HOUSE_ID} not found in dataset"
            rm -f dataset_temp.json house_data.json
            exit 1
          fi

          rm -f dataset_temp.json
          echo "House data extracted successfully"

      - name: Fetch AirROI enrichment data
        id: enrichment
        env:
          AIRROI_API_KEY: ${{ secrets.AIRROI_API_KEY }}
        run: |
          HOUSE_ID="${{ inputs.house_id }}"
          ENRICHMENT_DIR="houses/${HOUSE_ID}/enrichment"
          ENRICHMENT_FILE="${ENRICHMENT_DIR}/airroi_enrichment.json"

          # Check if enrichment already exists
          if [ -f "${ENRICHMENT_FILE}" ]; then
            echo "‚úÖ Enrichment data already exists, skipping AirROI API call"
            echo "exists=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "üì° Fetching enrichment data from AirROI API..."

          # Create enrichment directory
          mkdir -p "${ENRICHMENT_DIR}"

          python3 << 'EOF'
          import json
          import urllib.request
          import urllib.error
          import os
          from datetime import datetime, timezone

          API_KEY = os.environ.get('AIRROI_API_KEY')

          if not API_KEY:
              print("‚ö†Ô∏è  No AirROI API key configured, skipping enrichment")
              # Create empty enrichment file
              with open('${{ env.ENRICHMENT_FILE }}', 'w') as f:
                  json.dump({'enriched': False, 'reason': 'No API key'}, f, indent=2)
              exit(0)

          # Load house data
          with open('house_data.json', 'r') as f:
              house_data = json.load(f)

          # Extract coordinates and property details
          lat = house_data.get('AddressDetails', {}).get('Latitude')
          lon = house_data.get('AddressDetails', {}).get('Longitude')
          bedrooms = house_data.get('FastView', {}).get('NumberOfBedrooms', 2)
          city = house_data.get('AddressDetails', {}).get('City', '')
          postcode = house_data.get('AddressDetails', {}).get('PostCode', '')

          # If no coordinates, try to geocode using postcode
          if not lat or not lon:
              if not postcode:
                  print("‚ö†Ô∏è  No coordinates and no postcode found, skipping enrichment")
                  with open('houses/${{ inputs.house_id }}/enrichment/airroi_enrichment.json', 'w') as f:
                      json.dump({'enriched': False, 'reason': 'No coordinates or postcode'}, f, indent=2)
                  exit(0)

              print(f"üó∫Ô∏è  Geocoding postcode {postcode} using Nominatim...")
              try:
                  # Use Nominatim (OpenStreetMap) for free geocoding
                  import time
                  time.sleep(1)  # Rate limit: 1 request per second

                  geocode_url = f"https://nominatim.openstreetmap.org/search?postalcode={postcode}&country=NL&format=json"
                  geocode_req = urllib.request.Request(
                      geocode_url,
                      headers={
                          'User-Agent': 'BNB-Analysis-Tool/1.0'  # Required by Nominatim
                      }
                  )

                  with urllib.request.urlopen(geocode_req, timeout=10) as response:
                      geocode_results = json.loads(response.read().decode())

                  if geocode_results and len(geocode_results) > 0:
                      lat = float(geocode_results[0]['lat'])
                      lon = float(geocode_results[0]['lon'])
                      print(f"  ‚úÖ Geocoded to ({lat}, {lon})")
                  else:
                      print(f"  ‚ùå Could not geocode postcode {postcode}")
                      with open('houses/${{ inputs.house_id }}/enrichment/airroi_enrichment.json', 'w') as f:
                          json.dump({'enriched': False, 'reason': 'Geocoding failed'}, f, indent=2)
                      exit(0)

              except Exception as e:
                  print(f"  ‚ùå Geocoding error: {e}")
                  with open('houses/${{ inputs.house_id }}/enrichment/airroi_enrichment.json', 'w') as f:
                      json.dump({'enriched': False, 'reason': f'Geocoding error: {str(e)}'}, f, indent=2)
                  exit(0)

          enrichment = {
              'enriched': True,
              'enriched_at': datetime.now(timezone.utc).isoformat(),
              'house_id': '${{ inputs.house_id }}',
              'coordinates': {
                  'latitude': lat,
                  'longitude': lon,
                  'source': 'geocoded' if (not house_data.get('AddressDetails', {}).get('Latitude')) else 'original'
              },
              'api_calls': 0,
              'estimated_cost': 0.0
          }

          try:
              # 1. Search for comparable listings within 5km radius
              print(f"Searching for comparable listings near {city} ({lat}, {lon})...")

              radius_search_url = "https://api.airroi.com/v2/listings/search/radius"
              radius_body = {
                  "latitude": lat,
                  "longitude": lon,
                  "radius_km": 5,
                  "filters": {
                      "bedrooms": {"eq": bedrooms}
                  },
                  "pagination": {
                      "page_size": 10,
                      "offset": 0
                  },
                  "currency": "native",
                  "metrics_period": "ttm"
              }

              radius_req = urllib.request.Request(
                  radius_search_url,
                  data=json.dumps(radius_body).encode(),
                  headers={
                      'X-API-KEY': API_KEY,
                      'Content-Type': 'application/json'
                  }
              )

              with urllib.request.urlopen(radius_req, timeout=30) as response:
                  comparables = json.loads(response.read().decode())

              enrichment['comparables'] = comparables.get('data', [])
              enrichment['api_calls'] += 1
              enrichment['estimated_cost'] += 0.01

              print(f"  ‚úÖ Found {len(enrichment['comparables'])} comparable listings")

              # 2. Get revenue estimate
              print(f"Fetching revenue estimate...")

              # Build query params
              params = {
                  'latitude': lat,
                  'longitude': lon,
                  'bedrooms': bedrooms
              }
              query_string = '&'.join([f"{k}={v}" for k, v in params.items()])
              estimate_url = f"https://api.airroi.com/v2/calculator/estimate?{query_string}"

              estimate_req = urllib.request.Request(
                  estimate_url,
                  headers={
                      'X-API-KEY': API_KEY,
                      'Content-Type': 'application/json'
                  }
              )

              with urllib.request.urlopen(estimate_req, timeout=30) as response:
                  revenue_estimate = json.loads(response.read().decode())

              enrichment['revenue_estimate'] = revenue_estimate.get('data', {})
              enrichment['api_calls'] += 1
              enrichment['estimated_cost'] += 0.01

              print(f"  ‚úÖ Revenue estimate fetched")

              print(f"\n{'='*60}")
              print(f"Enrichment Summary:")
              print(f"  API calls: {enrichment['api_calls']}")
              print(f"  Estimated cost: ${enrichment['estimated_cost']:.2f}")
              print(f"  Comparables found: {len(enrichment.get('comparables', []))}")
              print(f"{'='*60}")

          except urllib.error.HTTPError as e:
              print(f"‚ùå AirROI API Error {e.code}: {e.reason}")
              enrichment['enriched'] = False
              enrichment['error'] = f"HTTP {e.code}: {e.reason}"
          except Exception as e:
              print(f"‚ùå Error fetching enrichment: {e}")
              enrichment['enriched'] = False
              enrichment['error'] = str(e)

          # Save enrichment data
          with open('houses/${{ inputs.house_id }}/enrichment/airroi_enrichment.json', 'w') as f:
              json.dump(enrichment, f, indent=2)

          print(f"‚úÖ Enrichment data saved")
          EOF

          echo "exists=false" >> $GITHUB_OUTPUT

      - name: Run analysis
        id: analyze
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python -c "
          import json
          from src.agent import HouseAnalysisAgent
          from pathlib import Path

          # Load house data
          with open('house_data.json', 'r') as f:
              house_data = json.load(f)

          # Load enrichment data if available
          enrichment_path = Path('houses') / '${{ inputs.house_id }}' / 'enrichment' / 'airroi_enrichment.json'
          enrichment_data = None
          if enrichment_path.exists():
              with open(enrichment_path, 'r') as f:
                  enrichment_data = json.load(f)
              print(f'‚úÖ Loaded enrichment data (enriched: {enrichment_data.get(\"enriched\", False)})')
          else:
              print('‚ö†Ô∏è  No enrichment data found')

          # Load market metrics if available
          market_metrics_path = Path('data') / 'market_metrics.json'
          market_metrics = None
          if market_metrics_path.exists():
              with open(market_metrics_path, 'r') as f:
                  market_data = json.load(f)
                  city = house_data.get('AddressDetails', {}).get('City')
                  if city and city in market_data.get('cities', {}):
                      market_metrics = market_data['cities'][city]
                      print(f'‚úÖ Loaded market metrics for {city}')

          # Initialize agent
          agent = HouseAnalysisAgent(
              rules_version='${{ inputs.rules_version }}',
              llm_provider='${{ inputs.llm_provider }}'
          )

          # Run analysis with enrichment data
          analysis = agent.analyze_house(
              house_data=house_data,
              house_id='${{ inputs.house_id }}',
              apify_dataset_id='Yb4fTMJ9wQsuyZf3L',  # Hardcoded dataset ID
              enrichment_data=enrichment_data,
              market_metrics=market_metrics
          )

          # Validate
          agent.validate_analysis(analysis)

          # Save analysis
          house_dir = Path('houses') / '${{ inputs.house_id }}'
          house_dir.mkdir(parents=True, exist_ok=True)

          # Save to analyses directory with version and timestamp
          analyses_dir = house_dir / 'analyses'
          analyses_dir.mkdir(exist_ok=True)

          timestamp = analysis['analyzed_at'].replace(':', '-').split('.')[0]
          filename = f\"{analysis['rules_version']}_{timestamp}.json\"
          analysis_path = analyses_dir / filename

          with open(analysis_path, 'w') as f:
              json.dump(analysis, f, indent=2)

          print(f'Analysis saved to: {analysis_path}')

          # Also save raw data if not exists
          raw_dir = house_dir / 'raw'
          raw_dir.mkdir(exist_ok=True)
          raw_path = raw_dir / f'data_{timestamp}.json'

          with open(raw_path, 'w') as f:
              json.dump(house_data, f, indent=2)

          # Save latest analysis reference
          with open(house_dir / 'latest_analysis.json', 'w') as f:
              json.dump({
                  'analyzed_at': analysis['analyzed_at'],
                  'rules_version': analysis['rules_version'],
                  'overall_score': analysis['overall_score'],
                  'analysis_file': str(analysis_path.relative_to(house_dir))
              }, f, indent=2)

          # Output for next steps
          print(f'::set-output name=score::{analysis[\"overall_score\"]}')
          print(f'::set-output name=analysis_path::{analysis_path}')
          "

      - name: Generate HTML and Markdown reports
        run: |
          python -c "
          import json
          import os
          from pathlib import Path
          from src.report_generator import ReportGenerator
          from src.markdown_generator import MarkdownGenerator

          # Load latest analysis
          house_dir = Path('houses') / '${{ inputs.house_id }}'
          with open(house_dir / 'latest_analysis.json', 'r') as f:
              latest = json.load(f)

          analysis_file = house_dir / latest['analysis_file']
          with open(analysis_file, 'r') as f:
              analysis = json.load(f)

          reports_dir = house_dir / 'reports'
          reports_dir.mkdir(exist_ok=True)

          timestamp = analysis['analyzed_at'].replace(':', '-').split('.')[0]
          base_filename = f\"{analysis['rules_version']}_{timestamp}\"

          # Generate HTML report
          html_generator = ReportGenerator()
          html_path = reports_dir / f'{base_filename}.html'
          html_generator.save(analysis, html_path)
          print(f'HTML report generated: {html_path}')

          # Generate Markdown report
          md_generator = MarkdownGenerator()
          md_path = reports_dir / f'{base_filename}.md'
          md_generator.save(analysis, md_path)
          print(f'Markdown report generated: {md_path}')

          # Create symlinks to latest reports
          latest_html = reports_dir / 'latest.html'
          latest_md = reports_dir / 'latest.md'

          # Remove old symlinks if they exist
          if latest_html.exists() or latest_html.is_symlink():
              latest_html.unlink()
          if latest_md.exists() or latest_md.is_symlink():
              latest_md.unlink()

          # Create new symlinks (relative paths for git)
          os.symlink(f'{base_filename}.html', latest_html)
          os.symlink(f'{base_filename}.md', latest_md)
          print(f'Symlinks created: latest.html -> {base_filename}.html')
          print(f'Symlinks created: latest.md -> {base_filename}.md')
          "

      - name: Update analysis scores index
        run: |
          python -c "
          import json
          from pathlib import Path
          from datetime import datetime, timezone

          # Load current scores index
          scores_file = Path('data/analysis_scores.json')
          if scores_file.exists():
              with open(scores_file, 'r') as f:
                  scores_data = json.load(f)
          else:
              scores_data = {'last_updated': '', 'houses': {}}

          # Load latest analysis
          house_dir = Path('houses') / '${{ inputs.house_id }}'
          with open(house_dir / 'latest_analysis.json', 'r') as f:
              latest = json.load(f)

          # Update scores index
          scores_data['last_updated'] = datetime.now(timezone.utc).isoformat()
          scores_data['houses']['${{ inputs.house_id }}'] = {
              'score': latest['overall_score'],
              'analyzed_at': latest['analyzed_at'],
              'rules_version': latest['rules_version']
          }

          # Save updated index
          with open(scores_file, 'w') as f:
              json.dump(scores_data, f, indent=2)

          print(f'Updated scores index for house ${{ inputs.house_id }}')
          "

      - name: Commit and push analysis results to main
        run: |
          git config user.name "House Analysis Bot"
          git config user.email "bot@github-actions"

          git add houses/${{ inputs.house_id }}/ data/analysis_scores.json

          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Analysis: ${{ inputs.house_id }} using ${{ inputs.rules_version }} (score: ${{ steps.analyze.outputs.score }})"

            # Retry push up to 3 times in case of concurrent workflow conflicts
            max_attempts=3
            attempt=1
            while [ $attempt -le $max_attempts ]; do
              echo "Push attempt $attempt of $max_attempts..."

              if git push origin main; then
                echo "‚úÖ Analysis results pushed to main branch"
                break
              else
                if [ $attempt -lt $max_attempts ]; then
                  echo "Push failed, pulling and retrying..."
                  git pull --rebase origin main
                  attempt=$((attempt + 1))
                  sleep $((attempt * 2))  # Exponential backoff
                else
                  echo "‚ùå Failed to push after $max_attempts attempts"
                  exit 1
                fi
              fi
            done
          fi
